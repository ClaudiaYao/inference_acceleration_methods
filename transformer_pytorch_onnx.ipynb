{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5mEW3laLcZ2",
    "outputId": "de078d5e-9592-45d6-d653-92ba8b927d55"
   },
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install -U \"nvidia_modelopt[hf]\"\n",
    "!pip install onnx\n",
    "!pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ipMFf8hd51C",
    "outputId": "2dd25686-bdb5-4308-c49d-cd233819a347"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348,
     "referenced_widgets": [
      "d41158985f2343069428548b4be42e43",
      "0d149c90118f4ea2b5f458b2251fc279",
      "ad8dd74f7a54429d892c997798122dfe",
      "ab4169d4a8224d67bb0f7835f03034c1",
      "330ce81e75064b68b63c11e9931843b9",
      "ef607678ccf14cafb7d8d6cd810fa89c",
      "c3cd44b0d1154a3991fd82302aecf0dd",
      "24c5e82e68a84b8f90505af07406984b",
      "caa310575cac425c963fb0ef3ec7d506",
      "672c5fcd421b4857ac4c03e1a0d2e4f8",
      "027a7e14244c4dd4b6511441cd902d23",
      "914af4d7c1b049a7b78afc16d2a539fe",
      "9d38692d0b7245dd8148fb4d25544db7",
      "dbcfbe2b264848e79546bb70160ffc2d",
      "072a926666624e36b45d9f249c27d010",
      "8a9a911c429443f9bd0e7b441da16225",
      "ecb4c8ea05ed460b9815c9faf8a08cb7",
      "b3c3284bbefe4790899835ec740da5dd",
      "1a0a699c6fd7476f94d0755694c5b574",
      "0fc5c0b9656242c69f51fa3a7fbaaa0a",
      "07aa32f323704e7a983cdd45fdbc37ac",
      "dc27b0a0011248819e05ef078a5d45e7",
      "340efe242ee548dba23d680e28ba6262",
      "9e06322bf6ff48cb9e6bc58d68d747c5",
      "f2f5ce852032481fadb6450e0589b643",
      "8adcce456be64f988c2ff9d77af2084a",
      "c2103d6a69ac4d26b2b5060d5acfac4d",
      "767a3f0a96714898b0fe098530f1d433",
      "0a9f97270f8b4e1ab97178d11831db82",
      "b3b9f1b313744f2da1cf225fc37800b4",
      "0b23143404194115898ee236563c050a",
      "76a252b281ad4c53b525f12f36fb4471",
      "36b67bb762524f928cd382bcec051dfd",
      "7d4e6161659244e989815e3943712dbb",
      "75c7856222ae4f83aea42c2c37024867",
      "0e2b0b4726504b74a6bb0be234a8a3d4",
      "784e09caf7d04d89ac89bfe3ac444158",
      "a766f249c1514bb7963f7cf7c08c71d9",
      "96e03bc002504da49fbc9763509cc4f8",
      "7205a1920e8e492d8b788ef97edfca27",
      "878320cecb3c4a83a0f9a5baff9f44ca",
      "3f2db9e2c80e433480cddad2be442595",
      "93ba6aba34d046a4a52c7df63483f7fd",
      "eb59c5afa5f44e75a982b067c500a615",
      "0794aeb557b6401bb4e499b5702362e9",
      "0f28f1cd4a0148ddb3f78399f525e61c",
      "3789c6b76b4642929a866b312233ccb0",
      "ba5cd28a9f2b49bfa1bed139b03c0330",
      "f9da32b27b504a7b99d86408d82f5012",
      "7869d1a7ba43453a990cd34e714d6202",
      "8ccf2b3de08c4c64b9f6753c6c4863a1",
      "bf1ffd7cd3fc4ebc826aba01340e61cf",
      "6802dd7bd95b4d3eb29a7e24dc9f7d0f",
      "eba5319d114b4c5fadbdb272f1ba74e3",
      "aad72c51d54c4ae1b2434827df2dc3bb",
      "feb0eb306707441e800ab7cb42ee5af3",
      "86beb61765634449bca060037a718d16",
      "2c906a7e10ee41959616f22b53a1e662",
      "1aeddad78f90498b92a6859aaa69caaf",
      "d2615c264ad84f8b91e9538c0db5b50a",
      "e07e58ac13cc408bbc4cd268a28a7d50",
      "c9008a39e7784defaaffd93af5b8394a",
      "900b5e9255c043d2b768505d319dc92c",
      "3732118bb4b349de9f3812985b81c539",
      "a988e70f5661493ab790a4011f54f8c2",
      "438fd172e0ce4106a68c4b9a5acc1db3"
     ]
    },
    "id": "JJnZ9_1FMwb2",
    "outputId": "f564707b-338d-44ac-eeaf-f987001dcad7"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# 1. Load model & tokenizer\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).eval().cuda()\n",
    "\n",
    "# 2. Example batch of sentences\n",
    "text = \"\"\" A good story encourages us to turn the next page and read more. We want to find out what happens next and what the main characters do and what they say to each other.\n",
    "We may feel excited, sad, afraid, angry or really happy. This is because the experience of reading or listening to a story is much more likely to make us 'feel' that we are part\n",
    "of the story, too. Just like in our 'real' lives, we might love or hate different characters in the story. Perhaps we recognise ourselves or others in some of them. Perhaps we\n",
    "have similar problems. Because of this natural empathy with the characters, our brains process the reading of stories differently from the way we read factual information.\n",
    "Our brains don't always recognise the difference between an imagined situation and a real one so the characters become 'alive' to us. What they say and do is therefore more meaningful.\n",
    "This is why the words and structures that relate a story's events, descriptions and conversations are processed in this deeper way. In fact, cultures all around the world have always\n",
    "used storytelling to pass knowledge from one generation to another. Our ancestors understood very well that this was the best way to make sure our histories and information about\n",
    "how to relate to others and to our world was not only understood, but remembered too. (Notice that the word ‘history’ contains the word ‘story’ – More accurately, the word ‘story’\n",
    "derives from ‘history’.) Encouraging your child to read or listen to stories should therefore help them to learn a second language in a way that is not only fun, but memorable.\n",
    "Let's take a quick look at learning vocabulary within a factual text or within a story. Imagine the readers are eight-year-olds interested in animals. In your opinion, are they more\n",
    "likely to remember AND want to continue reading the first or second text? \"\"\"\n",
    "\n",
    "texts = [item.strip() for item in text.split(\".\")][:16]  # adjust batch size here\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=32).to(\"cuda\")\n",
    "\n",
    "input_ids = inputs[\"input_ids\"].to(torch.int32)\n",
    "attention_mask = inputs[\"attention_mask\"].to(torch.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xCZ73F3PM29t",
    "outputId": "28f738ba-770a-46f2-ef4b-05613a2fa4f9"
   },
   "outputs": [],
   "source": [
    "# 3. Baseline PyTorch inference\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    baseline_outputs = model(input_ids, attention_mask)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    baseline_time = end - start\n",
    "    print(f\"PyTorch latency: {baseline_time:.4f} sec\")\n",
    "\n",
    "print(\"Output shape (PyTorch):\", baseline_outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEKcqvCaM7Ea",
    "outputId": "7f0f2a73-9a61-45e8-d6a4-7969fbacfc59"
   },
   "outputs": [],
   "source": [
    "# save to onnx\n",
    "output_onnx_file = \"roberta.onnx\"\n",
    "torch.onnx.export(\n",
    "    model.float(),\n",
    "    (input_ids, attention_mask),\n",
    "    output_onnx_file,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"logits\", \"other\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "        \"logits\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "        \"other\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=17\n",
    ")\n",
    "\n",
    "print(\"save to onnx file:\", output_onnx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIiBT19SNlgu"
   },
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "def run_onnx(onnx_model_pth, provider: str):\n",
    "    input_ids_np = inputs[\"input_ids\"].to(torch.int32).cpu().numpy()\n",
    "    attention_mask_np = inputs[\"attention_mask\"].to(torch.int32).cpu().numpy()\n",
    "\n",
    "    # 4. Onnx inference\n",
    "    sess = ort.InferenceSession(onnx_model_pth, providers=[provider])\n",
    "\n",
    "    # Check available providers\n",
    "    print(\"Available providers:\", ort.get_available_providers())\n",
    "    print(\"Current provider:\", sess.get_providers())\n",
    "\n",
    "    start = time.time()\n",
    "    onnx_outputs = sess.run(None, {\"input_ids\": input_ids_np, \"attention_mask\": attention_mask_np})\n",
    "    end = time.time()\n",
    "    onnx_time = end - start\n",
    "    print(f\"onnx runtime latency: {onnx_time:.4f} sec\")\n",
    "    return onnx_outputs\n",
    "\n",
    "def measure_numeric_diff(onnx_tensor, pytorch_base_tensor):\n",
    "    diff = np.abs(pytorch_base_tensor - onnx_tensor)\n",
    "    diff_mean = diff.mean()\n",
    "    diff_max = diff.max()\n",
    "    diff_percent = (diff > 0.1).mean() * 100\n",
    "\n",
    "    print(\"Mean absolute difference:\", diff_mean)\n",
    "    print(\"Max absolute difference:\", diff_max)\n",
    "    print(\"Percentage of values with diff > 0.01:\", diff_percent, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2_9TICJOQBf",
    "outputId": "3ef38115-5bba-46c3-84e6-f0cc175492b1"
   },
   "outputs": [],
   "source": [
    "onnx_outputs = run_onnx(\"roberta.onnx\", \"CUDAExecutionProvider\")\n",
    "\n",
    "onnx_tensor = onnx_outputs[0]  # for last_hidden_state\n",
    "pytorch_base_tensor = baseline_outputs.last_hidden_state.cpu().numpy()\n",
    "measure_numeric_diff(onnx_tensor, pytorch_base_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBGfgnEnfD9M",
    "outputId": "b9ff7cf6-a72c-4125-e6b1-9235a3b65262"
   },
   "outputs": [],
   "source": [
    "onnx_outputs_cpu = run_onnx(\"roberta.onnx\", \"CPUExecutionProvider\")\n",
    "\n",
    "onnx_tensor_cpu = onnx_outputs_cpu[0]  # for last_hidden_state\n",
    "pytorch_base_tensor = baseline_outputs.last_hidden_state.cpu().numpy()\n",
    "measure_numeric_diff(onnx_tensor_cpu, pytorch_base_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6IL-3zxh8Dg",
    "outputId": "1d92bc0e-a5af-4af9-b661-758b1d6b42ed"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y build-essential cmake\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install onnxsim --use-pep517 --no-build-isolation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9C6t1TpffQzC",
    "outputId": "2f9c0f90-7341-433b-c6e8-9a1e0582a16c"
   },
   "outputs": [],
   "source": [
    "!onnxsim roberta.onnx roberta_simplified.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaEHDN0bnUot",
    "outputId": "35ce0183-4fcf-4835-a554-b2a0324e3f23"
   },
   "outputs": [],
   "source": [
    "onnx_outputs_cpu = run_onnx(\"roberta_simplified.onnx\", \"CUDAExecutionProvider\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
