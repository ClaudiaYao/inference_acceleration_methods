{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddecc733-807f-4786-add9-115e5a3d8276",
    "outputId": "363d5fe6-66c6-4dff-fbf7-b7c016988bca"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install torch-tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aab496c2-8f21-4f0a-ad7a-fe417f974f0e",
    "outputId": "012bee23-3814-4883-ebe0-327739b858c6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "aT4p3v3f9ntl"
   },
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437,
     "referenced_widgets": [
      "882853d1334142c2acf7fd1e79951a2c",
      "50a959c757ee4250a2f69726c55e5020",
      "5459a9047e29417fbe6df2cd9090241b",
      "fa40856abfed453b8e5dde8159624ba0",
      "76bf5a2e2f1e4561beb57cceb3998afd",
      "4e1b245caee945b080cb86bbe27bc6d1",
      "023d1b5d904e42788ebc6974ae062c69",
      "2e9eb85c22eb45a0a1bcb72f02081637",
      "7ae61917dbf54f4ead07b020cc31e126",
      "1d37bc14f37844bf929884989d07f15f",
      "445114b1e5334290b2ca5daba5698de0",
      "ce35f79c4cf2429b87e687a44816cc5b",
      "6fce1eb152e54d7387e5421abdc817f4",
      "11b84fc9d9bf4762b6fb7381881aefde",
      "3745f0b1999742d5ac4a972f8bd5c4c3",
      "b8716bb86f54417293c25d95f1ee8599",
      "e1b5fc27ac4b4d7bbfba29e51467964a",
      "c85bd9466f5d408c8ee318854e555bcb",
      "417c693ef5304b9ea367f376dd492d36",
      "bef0ddb3f2674e788b51fd03dc800fc8",
      "2587f23fd466449391fb89c6624ad0bb",
      "822097b01e2040bdbe455356d80a76dc",
      "1fa4ace3cf1041c4b6a36f4ef395680e",
      "b89954a9439647f1b38470b63e01e769",
      "cbe7b20dab8c4fe7b303db17a3ceb072",
      "b90cd533ec354c07b0b2031c0779c28a",
      "39a79d221be74dceaa9ac617dacd8339",
      "f53b3ef576c64c27986989cb1684f4b7",
      "b113eee572ac4569ac505b650addbf45",
      "0cf795809c944e4a89d33f41b13b1009",
      "a6fe28c729dc44d98f3d4a3dc9594b43",
      "d29c3dfcc5ec440cae95b5cb3bc5b9ab",
      "20a77a1126354076acb96d2f03fa9cfe",
      "8974e22eb6794fb3a92491fafc0577b5",
      "bf431289eb19420692134c0eefffe504",
      "d38fc386079c4e908ff6aae183996737",
      "fb7c4f502703406c92ce62c7680c1578",
      "f4f4d2bce9904b70a543c639a4f7c2a1",
      "59d7f1ad7a834c8e82280c37024fcb67",
      "0c959a3650f44feca0b29cba2c73e460",
      "91f7d4a12994417f8f93dba6c78fda6b",
      "cb5d0bcf338345f29c0fa2cbe91e5207",
      "fb308d3458a846009c6dcde80ad93ed6",
      "80e64902e22c4c7597766f3a72fe730f",
      "80bcac40526a499ea9816983628ed42c",
      "55634a68b7144051bfd3bbbc29d50672",
      "f40e1d2820ff40afbd8e98759f25a5ab",
      "8e016d7c1fe847b1ac976f18a1771cd0",
      "bceab8c61b6f479f897259eb94af53d0",
      "cdbcaaee215a416d9ccf9b011be80d1b",
      "44f2fdcd45324e95b50a16fb7e77dc41",
      "8771cc90a9824223befac144e0a71d3f",
      "32c7e96bea9c495a984d5a53473e124d",
      "31e3996a7351484381610fc6f380dea3",
      "150897c044cd4f459560f48a3228966d",
      "d9619382818a4ecc89378b5e4baf2d79",
      "25d32e43d84c4202b34814f50f11b70a",
      "ab6c1426488647ae95920d488ce60367",
      "d39c4c86d34047e6adaf8946aa6d553d",
      "ce5969f614a64a9dba3058ebb216325e",
      "de4e79e7e3ff4cfc9d90dfc814e86444",
      "101d81d58b93425aa1278011813d64db",
      "b6e1054c0f384c16b17309cd5f885b43",
      "6e7e479b1cb94b64aa3011018ab36e43",
      "a37d01b3c4ab40499d09192e6ee1f4f1",
      "63d2a162449a47bd81542e5ee0aa4aaa"
     ]
    },
    "id": "4e21c922-eaeb-4d26-b833-b462f252bd0e",
    "outputId": "2770a3af-0754-4c24-c340-c41dfe35c3ab"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch_tensorrt\n",
    "\n",
    "# 1. Load model & tokenizer\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).eval().cuda()\n",
    "\n",
    "# 2. Example batch of sentences\n",
    "text = \"\"\" A good story encourages us to turn the next page and read more. We want to find out what happens next and what the main characters do and what they say to each other.\n",
    "We may feel excited, sad, afraid, angry or really happy. This is because the experience of reading or listening to a story is much more likely to make us 'feel' that we are part\n",
    "of the story, too. Just like in our 'real' lives, we might love or hate different characters in the story. Perhaps we recognise ourselves or others in some of them. Perhaps we\n",
    "have similar problems. Because of this natural empathy with the characters, our brains process the reading of stories differently from the way we read factual information.\n",
    "Our brains don't always recognise the difference between an imagined situation and a real one so the characters become 'alive' to us. What they say and do is therefore more meaningful.\n",
    "This is why the words and structures that relate a story's events, descriptions and conversations are processed in this deeper way. In fact, cultures all around the world have always\n",
    "used storytelling to pass knowledge from one generation to another. Our ancestors understood very well that this was the best way to make sure our histories and information about\n",
    "how to relate to others and to our world was not only understood, but remembered too. (Notice that the word ‘history’ contains the word ‘story’ – More accurately, the word ‘story’\n",
    "derives from ‘history’.) Encouraging your child to read or listen to stories should therefore help them to learn a second language in a way that is not only fun, but memorable.\n",
    "Let's take a quick look at learning vocabulary within a factual text or within a story. Imagine the readers are eight-year-olds interested in animals. In your opinion, are they more\n",
    "likely to remember AND want to continue reading the first or second text? \"\"\"\n",
    "\n",
    "texts = [item.strip() for item in text.split(\".\")][:16]  # adjust batch size here\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=32).to(\"cuda\")\n",
    "\n",
    "input_ids = inputs[\"input_ids\"].to(torch.int32)\n",
    "attention_mask = inputs[\"attention_mask\"].to(torch.int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "DCwlMZxd92mw"
   },
   "source": [
    "# Run Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rao2zT3M9wLB",
    "outputId": "ac88a03d-5f60-4bc4-f25e-8590f609f2a7"
   },
   "outputs": [],
   "source": [
    "# 3. Baseline PyTorch inference\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    baseline_outputs = model(input_ids, attention_mask)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    baseline_time = end - start\n",
    "    print(f\"PyTorch latency: {baseline_time:.4f} sec\")\n",
    "\n",
    "print(\"Output shape (PyTorch):\", baseline_outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "PGvopDLm97bR"
   },
   "source": [
    "# Convert Pytorch Model into TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnbCBJb1-rHr",
    "outputId": "e8c2a75c-69e8-480c-fafe-e5072f77764c"
   },
   "outputs": [],
   "source": [
    "# 4. Convert model with Torch-TensorRT with enabled_precision of torch.float16\n",
    "trt_model_float16 = torch_tensorrt.compile(\n",
    "    model,\n",
    "    inputs=[\n",
    "        torch_tensorrt.Input(min_shape=[1, 32], opt_shape=[8, 32], max_shape=[16, 32], dtype=torch.int32),  # input_ids\n",
    "        torch_tensorrt.Input(min_shape=[1, 32], opt_shape=[8, 32], max_shape=[16, 32], dtype=torch.int32),  # attention_mask\n",
    "    ],\n",
    "    enabled_precisions={torch.float16},\n",
    ")\n",
    "\n",
    "trt_inputs = {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask\n",
    "}\n",
    "\n",
    "print(\"Convert to TensorRT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4isRibjSXjFj",
    "outputId": "5acdf693-8d49-42db-a581-f9f6fbbee4c8"
   },
   "outputs": [],
   "source": [
    "# run model trt_model_float16\n",
    "start = time.time()\n",
    "trt_outputs_float16 = trt_model_float16(**trt_inputs)\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "trt_time_float16 = end - start\n",
    "print(f\"Torch-TensorRT latency: {trt_time_float16:.4f} sec\")\n",
    "\n",
    "print(\"Output shape (TensorRT):\", trt_outputs_float16.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyWByR6-4JAz",
    "outputId": "7a06d20d-ed58-4131-f994-73ed9483a711"
   },
   "outputs": [],
   "source": [
    "# 4. Convert model with Torch-TensorRT with enabled_precision of torch.float32\n",
    "trt_model_float32 = torch_tensorrt.compile(\n",
    "    model,\n",
    "    inputs=[\n",
    "        torch_tensorrt.Input(min_shape=[1, 32], opt_shape=[8, 32], max_shape=[16, 32], dtype=torch.int32),  # input_ids\n",
    "        torch_tensorrt.Input(min_shape=[1, 32], opt_shape=[8, 32], max_shape=[16, 32], dtype=torch.int32),  # attention_mask\n",
    "    ],\n",
    "    enabled_precisions={torch.float32},\n",
    ")\n",
    "\n",
    "trt_inputs_float32 = {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8VOz-kAYIba",
    "outputId": "e751a543-bbf9-4d4c-a62c-b99bd9fc4443"
   },
   "outputs": [],
   "source": [
    "# run model trt_model_float32\n",
    "start = time.time()\n",
    "trt_outputs_float32 = trt_model_float32(**trt_inputs_float32)\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "trt_time_float32 = end - start\n",
    "print(f\"Torch-TensorRT latency: {trt_time_float32:.4f} sec\")\n",
    "\n",
    "print(\"Output shape (TensorRT):\", trt_outputs_float32.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "8ZvuF6to-CUT"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "nXTbzp4MeDox"
   },
   "source": [
    "## Inference numerical difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfc0577f-6ee7-4b8a-9d7e-4beb4f8b39f8",
    "outputId": "b39fb6c0-8a5f-47cc-9e5b-35c68451fe4d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "diff_tensor_float16 = torch.abs(baseline_outputs.last_hidden_state - trt_outputs_float16.last_hidden_state)\n",
    "\n",
    "max_diff_float16 = diff_tensor_float16.max().item()\n",
    "min_diff_float16 = diff_tensor_float16.min().item()\n",
    "\n",
    "# 2️⃣ Percentage of elements > 0.1\n",
    "threshold = 0.01\n",
    "percent_over_threshold_float16 = (diff_tensor_float16 > threshold).float().mean().item() * 100\n",
    "\n",
    "print(f\"Max absolute difference: {max_diff_float16}\")\n",
    "print(f\"Min absolute difference: {min_diff_float16}\")\n",
    "print(f\"Percentage of elements > {threshold}: {percent_over_threshold_float16:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbf0qGgG4ouG",
    "outputId": "02bf9711-9ea5-402f-9206-bd3b613aacd0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "diff_tensor_float32 = torch.abs(baseline_outputs.last_hidden_state - trt_outputs_float32.last_hidden_state)\n",
    "\n",
    "max_diff_float32 = diff_tensor_float32.max().item()\n",
    "min_diff_float32 = diff_tensor_float32.min().item()\n",
    "\n",
    "threshold = 0.0001\n",
    "percent_over_threshold_float32 = (diff_tensor_float32 > threshold).float().mean().item() * 100\n",
    "\n",
    "print(f\"Max absolute difference: {max_diff_float32}\")\n",
    "print(f\"Min absolute difference: {min_diff_float32}\")\n",
    "print(f\"Percentage of elements > {threshold}: {percent_over_threshold_float32:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "KnDiU98zeLyJ"
   },
   "source": [
    "## Inference time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "dc086f65-86b4-4fd4-8b62-5ce5eb4f785a",
    "outputId": "13a00919-eb3c-4f37-cb1d-c0abc9c096c7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inference_time = [baseline_time, trt_time_float16, trt_time_float32]\n",
    "labels = ['Baseline', 'TRT Float16', \"TRT Float32\"]\n",
    "\n",
    "plt.bar(labels, inference_time, width=0.3, color=['blue', 'orange', 'green'])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.ylabel('Inference Time')\n",
    "plt.title('Inference Time Comparison')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "8379f577-2016-478b-aeab-42e2fee5b5f5",
    "outputId": "523941f5-1de0-4a85-f5ee-dddf40f71fa1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame({\"Inference_time\": [baseline_time, trt_time_float16, trt_time_float32],\n",
    "                     \"Inference_max_difference\": [np.nan, max_diff_float16, max_diff_float32],\n",
    "                     \"Infernce_Above_threshold_percentage (0.01)\": [np.nan, percent_over_threshold_float16, percent_over_threshold_float32]})\n",
    "\n",
    "data['Configure'] = ['Pytorch baseline', \"TensorRT float16\", \"TensorRT float32\"]\n",
    "data = data.set_index('Configure')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "SPHFoA-Y5QBl",
    "outputId": "53a3c49c-21d7-4ee7-9f6f-7266128b1a42"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "diff_flat_float16 = diff_tensor_float16.flatten().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.kdeplot(diff_flat_float16, label=\"TensorRT_float16\", fill=True, color=\"skyblue\", alpha=0.3, linewidth=2)\n",
    "\n",
    "plt.xlim(0, 0.03)\n",
    "plt.xlabel(\"Absolute Difference\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of Absolute Differences (KDE Curve) on TensorRT float16\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
